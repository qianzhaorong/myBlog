---
title: 随笔
images: 
date: 2018-07-22 22:25:27
tags: 第一周工作总结
categories: 随笔
---
  - 这一周是在德勤RA部门实习的第一周，通过这一周在公司的生活，确实让我在实际解决问题上的能力大大提高，那就来写下一周的总结吧。<!--more-->
  
  
  首先这一周总共写了大概十个左右的爬虫，平均每天两个，在这期间，遇到了不少困难，但是还是通过仔细的分析给解决了，同时也遇到了之前一直以为自己掌握了但实际上并没有真正掌握的知识，可谓收获颇多。
  
  
  首先遇到的第一个困难，就是需要的内容在一个div中，但是这个div的属性很奇特，是data-rectroot=""，当时就懵逼了，见都没见过，后面尝试了几次之后发现好像抓取不了，切换到开发者工具的network一栏获取请求信息，发现这个div的内容是通过异步请求的方式来获取的，这下看上去很明朗，于是构造好了请求，点击运行，准备躺一会，结果------403，是的，很尴尬，403那肯定是我被服务器认出来，于是去检查构造的头部字段，User-Agent有，Host也有，难道还有什么关键的字段，于是把Referer字段加上去试了试，我靠，竟然可以了，全都怪我太看不起Referer这个字段了。。。。
  
  第二个困难就是[惠誉中国](https://www.fitchratings.com/site/china)，当按照框架写完爬虫，点击运行，刚开始还没有什么问题，但是一杯水的时间，爬虫就访问不了网站了。能怎么办呢？只能找到问题所在。一开始的思路是以为惠誉中国将我的ip给封禁了，但是让我的组长去访问这个网站也访问不了，这就不是封禁我ip的问题啦！接着，又使用手机端访问，竟然可以访问！我靠，难道是这个网站对pc端的控制要严格一点？过了一段时间，这个网站在电脑上又可以正常访问了，于是便在爬虫程序中调整了一下访问网站的频率，原本是失败一次就停一分钟，这次每失败一次就在上一次停的时间的基础上加30s在访问，心想：这下应该可以了吧！没想到，这个网站果真是狡猾！还是抓取了一点数据后就不行了。于是仔细分析程序在访问哪个网址时出现的问题，运行了几次过后竟然发现程序每次到同一个网址后就不行了！这时我就猜想可能是这个网址的锅。于是去手机端验证，在访问这个页面一个网址后返回可以继续访问其他网址，但是！一旦访问了那个特殊的网址，就就就什么也访问不了了。这种情况之前还是在知乎上看见某前端工程师谈论过反爬虫机制中的钓鱼链接！又经过同事的测试，确实发现有一个链接是钓鱼链接。坑！总算找到问题所在，于是在程序中进行了修改，每次访问前检测一下这个url是不是和那个钓鱼链接的url相同，如果相同，就直接把它从列表中删除不访问了。但是这个解决方法有个弊端就是如果出现另一个钓鱼链接就没有办法检测了。于是想到了在每次访问前先使用能用的代理ip来访问这个url，如果代理ip访问不了，则这个链接就是钓鱼网址，同时这个方法还是有弊端，就是会增加时间上的成本，所以就没有使用这套方案。
  
  第三个困难就是一个繁体字转化为简体字的问题，这时候就得用上python的强大的第三方库langconv，经过一番尝试终于可以将繁体字通过langconv正常的转化为简体字了。
  
 同时也学会了如何在python2中处理获取到的网页出现乱码的问题，就是使用response.content属性获取到字节流再以网页的编码来decode，这样就不会出现乱码的问题了。因为之前一直使用的是python3，所以在编码问题上没有考虑很多，但是这次使用python2又让自己去复习了一遍编码，同时这次也着重研究了一下python解释器的编码和python的shell终端的编码，收获良多。下次可以专门写一篇文章来巩固一个python2的编码。
 
 这一个星期在公司一直写爬虫确实让自己知道了实践才能真正的记忆，而仅仅是记忆书本上的知识不去运用的话，遇到问题还是会不知道该怎么办。同时也让我知道了在爬虫中Referer这个字段的重要性！！！在这翻了好几次跟头，因为之前一直只知道有这么个字段却没有地方用，所以没有太重视它，没想到它给我上了一课！
 
 现在看见那些说自己爬取过知乎，微博等大网站的人说自己精通爬虫，只想笑笑，真正的困难在小网站上体现的更加明显！而自己以前也总是拿这些大网站说事，果真还是too young too naive。
 
 希望每个星期都能抽出一点时间来记录下所遇到的困难吧！下星期开始研究天眼查的复杂字体替换问题！